{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# format sig figs\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = r'J:\\Projects\\FasTrips\\chts\\output\\CHTS_fasttrips_demand_v0.2_stochastic_iter1_nocap\\CHTS_fasttrips_demand_v0.2_stochastic_iter1_nocap'\n",
    "\n",
    "# obs_links_dir = r'R:\\FastTrips\\FT Repo\\All input & output files\\OBS_FToutput.csv'\n",
    "# obs_links_dir = r'..\\data\\obs\\obs_links.csv'\n",
    "obs_links_dir = r'R:\\FastTrips\\CHTS & OBS ft_output\\CHTS_ft_output.csv'\n",
    "\n",
    "# Probability threshold for observed paths (are observed paths assigned above/below this value by fast-trips)\n",
    "threshold = 0.3\n",
    "\n",
    "# Compare observed path to pathset based on modes, agency, or route\n",
    "# comparison_field = 'path_modes'\n",
    "comparison_field = 'path_modes'\n",
    "# comparison_field = 'path_routes'\n",
    "\n",
    "non_transit_modes = ['transfer','walk_access','walk_egress','bike_access','bike_egress',\n",
    "                     'PNR_access','PNR_egress','KNR_access','KNR_egress']\n",
    "transit_mode_list = ['local_bus','commuter_rail','express_bus','ferry','heavy_rail','light_rail','premium_bus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_df(data, unique_fields, record_type=None):\n",
    "    '''Load text data as df, create unique trip record ID, and tag as model/observed record'''\n",
    "    df = pd.read_csv(data)\n",
    "    if record_type != None:\n",
    "        df['record_type'] = record_type    # tag as model/observed record\n",
    "\n",
    "    # Convert all specified unique_fields to string and concatenate as new unique_id field \n",
    "#     df[unique_fields] = pd.DataFrame([df[col].astype('int').astype('str') for col in unique_fields]).T\n",
    "#     df['unique_id'] = df[unique_fields].apply(lambda x: '_'.join(x), axis=1)\n",
    "    df['unique_id'] = df['person_id']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append(*args):\n",
    "    '''Union dataframes with similar structures'''\n",
    "    df = pd.DataFrame()\n",
    "    for data in args:\n",
    "        df = df.append(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_common_records(df1,df2,field):\n",
    "    '''Return dataframe of matching, common records only.\n",
    "       Example, person 1034 exists in df1, but not in df2, so new copy of df1 without 1034 is created\n",
    "    '''\n",
    "    df1 = df1[df1[field].isin(df2[field])]\n",
    "    df2 = df2[df2[field].isin(df1[field])]\n",
    "\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_transit_agency(df, routes):\n",
    "\n",
    "    df = pd.merge(left=df,right=routes[['route_id','agency_id']],on='route_id',how='left')\n",
    "\n",
    "    df['agency'] = df['agency_id']\n",
    "    df.drop('agency_id',axis=1)\n",
    "    df.fillna(\"\",inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def produce_path_fields(df, group):\n",
    "    '''\n",
    "    Concatenate set of fields for pathset_links, e.g. ('bart caltrain') for 2-leg transit trip\n",
    "    Produce concatenated fields for routes, modes, agencies, all components (stops, modes, & routes)\n",
    "    '''\n",
    "    # create \"path_routes\"\n",
    "\n",
    "#     for field in ['route_id','mode','agency','A_id','B_id']:\n",
    "    for field in ['mode']:\n",
    "        df[field] = df[field].astype('str')\n",
    "        df[field] = df[field].fillna(\"\")\n",
    "        df[field] = df[field].replace('nan',\"\")\n",
    "\n",
    "#     df['path_routes'] = df['route_id'].apply(lambda x: x.strip())\n",
    "#     path_routes = pd.DataFrame(df.groupby(group)['path_routes'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    \n",
    "#     result_df = pd.DataFrame(index=path_routes.index)\n",
    "#     result_df['path_routes'] = path_routes\n",
    "    \n",
    "    # create \"path_modes\"\n",
    "    df['path_modes'] = df['mode'].apply(lambda x: x.strip())\n",
    "    path_modes = pd.DataFrame(df.groupby(group)['mode'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    result_df = pd.DataFrame(index=path_modes.index)\n",
    "    result_df['path_modes'] = path_modes\n",
    "    \n",
    "#     # create \"path_agencies\"\n",
    "#     df['path_agencies'] = df['agency'].apply(lambda x: x.strip())\n",
    "#     result_df['path_agencies'] = pd.DataFrame(df.groupby(group)['agency'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "\n",
    "#     # Create \"path_components\"\n",
    "#     df['path_components'] = df['A_id']+\" \"+df['mode']+\" \"+df['route_id'] +\"_\"+ df['B_id']\n",
    "#     df['path_components'] = df['path_components'].apply(lambda x: x.strip())\n",
    "#     result_df['path_components'] = pd.DataFrame(df.groupby(group)['path_components'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    \n",
    "    # stop components\n",
    "#     df['path_stops'] = df['A_id'] +\" \"+df['B_id']\n",
    "#     df['path_stops'] = df['path_stops'].apply(lambda x: x.strip())\n",
    "#     result_df['path_stops'] = pd.DataFrame(df.groupby(group)['path_stops'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "#     # drop repeated records (A_id and B_id overlap as origin and destination nodes for subsequent trips)\n",
    "#     result_df['path_stops'] = result_df['path_stops'].apply(lambda row: np.unique(row.split(' ')))\n",
    "#     # write out as space separated field\n",
    "#     result_df['path_stops'] = result_df['path_stops'].apply(lambda x: \"%s\" % ' '.join(x).strip())\n",
    "    \n",
    "    # Return ID field from index\n",
    "    result_df['unique_id'] = result_df.index.get_level_values(0).values\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "routes = pd.read_csv(r'../data/gtfs/agency_route_1.9.csv')\n",
    "\n",
    "# Load observed and chosenpath_links; add new field designating 'model' or 'observed'\n",
    "obs = load_df(data=obs_links_dir, unique_fields=['person_id','trip_list_id_num'], record_type='observed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill floats with integers where available, specifically for stop IDs\n",
    "# obs.ix[obs['A_id'] != \"\",'A_id'] = obs.ix[obs['A_id'] != \"\",'A_id'].astype('float').astype('int') \n",
    "# obs.ix[obs['A_id'] != \"\",'A_id'] = obs.ix[obs['A_id'] != \"\",'A_id'].astype('float').astype('int') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpath_links = load_df(data=OUTPUT_DIR + r'\\chosenpaths_links.csv', \n",
    "    unique_fields=['person_id','trip_list_id_num'], record_type='model', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For some reason there are a lot of duplicates\n",
    "# let's drop them for now\n",
    "chosenpath_links = chosenpath_links.drop_duplicates()\n",
    "\n",
    "# Get the last iteration only\n",
    "chosenpath_links = chosenpath_links[chosenpath_links['iteration'] == chosenpath_links['iteration'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathset_paths = load_df(OUTPUT_DIR + r'\\pathset_paths.csv', unique_fields=['person_id','trip_list_id_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build comparison fields for pathset_links\n",
    "- from the description column in pathset_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mode_list(row):\n",
    "\n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    mode_results = []\n",
    "    \n",
    "    for field in row_array:\n",
    "        if field in transit_mode_list + ['transfer','walk_access','walk_egress']:\n",
    "            mode_results.append(field)\n",
    "\n",
    "    # convert from list into space-seperated string\n",
    "    mode_results = ' '.join(mode_results).strip()\n",
    "\n",
    "    return mode_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def route_list(row):\n",
    "    \"\"\"\n",
    "    if route_only=True, return only the route id from the trip id prepended with route info\n",
    "    otherwise return full route_id_xyz, where xyz is the trip id\n",
    "    \"\"\"\n",
    "    \n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    route_results = []\n",
    "    \n",
    "    for i in xrange(len(row_array)):\n",
    "        if row_array[i] in transit_mode_list:\n",
    "            route_results.append(\"_\".join(row_array[i+1].split('_')[:-1]))     # Drop last component of field (trip ID)\n",
    "#                 route_results.append(row_array[i+1])\n",
    "            \n",
    "    route_results =  ' '.join(route_results).strip()\n",
    "    \n",
    "    return route_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stop_list(row):\n",
    "    \n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    # Get the list of transit\n",
    "    trip_with_route_list = []\n",
    "    stop_results = []\n",
    "    \n",
    "    for i in xrange(len(row_array)):\n",
    "        if row_array[i] in transit_mode_list:\n",
    "            # Save this as a field we don't want to include as a stop\n",
    "            trip_with_route_list.append(row_array[i+1])\n",
    "        if row_array[i] not in trip_with_route_list+transit_mode_list+['transfer','walk_access','walk_egress']:\n",
    "            stop_results.append(row_array[i])\n",
    "    \n",
    "    stop_results = ' '.join(stop_results).strip()\n",
    "    \n",
    "    return stop_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agency_list(row):\n",
    "    \n",
    "    agency_results = []\n",
    "    \n",
    "    # Get list of agencies associated with each transit route\n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    for route_id in row_array:\n",
    "        agency_results.append(routes[routes['route_id'] == route_id]['agency_id'].values[0])\n",
    "    \n",
    "    agency_results = ' '.join(agency_results).strip()\n",
    "    \n",
    "    return agency_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mode paths\n",
    "pathset_paths['path_modes'] = pathset_paths['description'].apply(lambda row: mode_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Route paths\n",
    "pathset_paths['path_routes'] = pathset_paths['description'].apply(lambda row: route_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stops\n",
    "pathset_paths['path_stops'] = pathset_paths['description'].apply(lambda row: stop_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Agencies\n",
    "pathset_paths['path_agencies'] = pathset_paths['path_routes'].apply(lambda row: agency_list(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add transit agency field to chosenpath_links and pathset_links, based on route_id\n",
    "# chosenpath_links = add_transit_agency(df=chosenpath_links, routes=routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a stacked csv of observed trip links & model chosenpath_links; export for Tableau\n",
    "chosenpath_links, obs = select_common_records(chosenpath_links, obs,'person_id')\n",
    "append(chosenpath_links, obs).to_csv(OUTPUT_DIR + '/' + 'chosenpaths_links_with_observed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observed_path = produce_path_fields(obs, group=['unique_id'])\n",
    "modeled_path = produce_path_fields(chosenpath_links, group=['unique_id'])\n",
    "\n",
    "# Make sure we only evaluate the overlapping unique_id records\n",
    "observed_path = observed_path[observed_path['unique_id'].isin(modeled_path['unique_id'].values)]\n",
    "modeled_path = modeled_path[modeled_path['unique_id'].isin(observed_path['unique_id'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# observed_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine the observed and modeled path files\n",
    "df = pd.merge(observed_path, modeled_path, on='unique_id',suffixes=(\"_observed\",\"_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compare routes, modes, and agencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build list of routes used in observed and modeled trips\n",
    "# df['model_path_route_list'] = df['path_routes_model'].apply(lambda x: x.split(\" \"))\n",
    "# df['obs_path_route_list'] = df['path_routes_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# Build list of modes used in observed and modeled trips\n",
    "df['model_path_mode_list'] = df['path_modes_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_mode_list'] = df['path_modes_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# # Build list of transit agencies used in observed and modeled trips\n",
    "# df['model_path_agencies_list'] = df['path_agencies_model'].apply(lambda x: x.split(\" \"))\n",
    "# df['obs_path_agencies_list'] = df['path_agencies_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# # Build list of stops used in observed and modeled trips\n",
    "# df['model_path_stops_list'] = df['path_stops_model'].apply(lambda x: x.split(\" \"))\n",
    "# df['obs_path_stops_list'] = df['path_stops_observed'].apply(lambda x: x.split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Isolate transit modes only, because all trips should have walk & transfer components\n",
    "    \n",
    "df['model_transit_modes'] = df['model_path_mode_list'].apply(\n",
    "    lambda row: [element for element in row if element not in non_transit_modes])\n",
    "df['obs_transit_modes'] = df['obs_path_mode_list'].apply(\n",
    "    lambda row: [element for element in row if element not in non_transit_modes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_transit_modes</th>\n",
       "      <th>model_transit_modes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> [local_bus, heavy_rail, heavy_rail, other_bus,...</td>\n",
       "      <td> [heavy_rail, heavy_rail, local_bus, heavy_rail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>                                    [open_shuttle]</td>\n",
       "      <td>                                      [light_rail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> [local_bus, local_bus, premium_bus, premium_bu...</td>\n",
       "      <td>      [local_bus, local_bus, local_bus, local_bus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> [inter_regional_rail, , inter_regional_rail, i...</td>\n",
       "      <td>             [local_bus, premium_bus, premium_bus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>                 [local_bus, local_bus, local_bus]</td>\n",
       "      <td>    [express_bus, local_bus, local_bus, local_bus]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   obs_transit_modes  \\\n",
       "0  [local_bus, heavy_rail, heavy_rail, other_bus,...   \n",
       "1                                     [open_shuttle]   \n",
       "2  [local_bus, local_bus, premium_bus, premium_bu...   \n",
       "3  [inter_regional_rail, , inter_regional_rail, i...   \n",
       "4                  [local_bus, local_bus, local_bus]   \n",
       "\n",
       "                                 model_transit_modes  \n",
       "0  [heavy_rail, heavy_rail, local_bus, heavy_rail...  \n",
       "1                                       [light_rail]  \n",
       "2       [local_bus, local_bus, local_bus, local_bus]  \n",
       "3              [local_bus, premium_bus, premium_bus]  \n",
       "4     [express_bus, local_bus, local_bus, local_bus]  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['obs_transit_modes','model_transit_modes']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the intersection between the chosen model/observed paths using different criteria\n",
    "# Which are in common between model and observed?\n",
    "\n",
    "# transit route IDs only\n",
    "# df.apply(lambda row: all(i in row['model_path_route_list'] for i in row['obs_path_route_list']), axis=1)\n",
    "# df['routes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_route_list'], df['obs_path_route_list'])]\n",
    "\n",
    "# stops only\n",
    "# df.apply(lambda row: all(i in row['model_path_stops_list'] for i in row['obs_path_stops_list']), axis=1)\n",
    "# df['stops_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_stops_list'], df['obs_path_stops_list'])]\n",
    "\n",
    "# All Modes (including transfer, access/egress)\n",
    "df.apply(lambda row: all(i in row['model_path_mode_list'] for i in row['obs_path_mode_list']), axis=1)\n",
    "df['all_modes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_mode_list'], df['obs_path_mode_list'])]\n",
    "\n",
    "# Transit modes only (type of vehicle taken and number of boardings)\n",
    "df.apply(lambda row: all(i in row['model_path_mode_list'] for i in row['obs_path_mode_list']), axis=1)\n",
    "df['transit_modes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_transit_modes'], df['obs_transit_modes'])]\n",
    "\n",
    "# Agency Intersection\n",
    "# df.apply(lambda row: all(i in row['model_path_agencies_list'] for i in row['obs_path_agencies_list']), axis=1)\n",
    "# df['agency_intersection'] = \\\n",
    "#     [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_agencies_list'], \n",
    "#         df['obs_path_agencies_list'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exact Match of path routes, modes, & components\n",
    "# Isolate rows (trip legs) with matching path routes\n",
    "# complete_route_match = df[df['path_routes_observed'] == df['path_routes_model']]\n",
    "complete_mode_match = df[df['path_modes_observed'] == df['path_modes_model']]\n",
    "# complete_agency_match = df[df['path_agencies_observed'] == df['path_agencies_model']]\n",
    "# complete_stop_match = df[df['path_stops_observed'] == df['path_stops_model']]\n",
    "\n",
    "# complete_route_match['complete_route_match'] = 1\n",
    "complete_mode_match['complete_mode_match'] = 1\n",
    "# complete_agency_match['complete_agency_match'] = 1\n",
    "# complete_stop_match['complete_stop_match'] = 1\n",
    "\n",
    "# Add new columns to the larger dataframe indicating if the row is a complete match\n",
    "df = pd.merge(df, complete_mode_match[['unique_id','complete_mode_match']], how='left', on='unique_id')\n",
    "\n",
    "\n",
    "# df = pd.merge(df, complete_route_match[['unique_id','complete_route_match']], how='left', on='unique_id')\n",
    "# df = pd.merge(df, complete_agency_match[['unique_id','complete_agency_match']], how='left', on='unique_id')\n",
    "# df = pd.merge(df, complete_stop_match[['unique_id','complete_stop_match']], how='left', on='unique_id')\n",
    "\n",
    "# for field in ['mode','route','agency', 'stop']:\n",
    "for field in ['mode']:\n",
    "    df['complete_'+field+'_match']=  df['complete_'+field+'_match'].replace('nan',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we find the percent of trips with matching routes or partial matching routes\n",
    "\n",
    "# Join the filtered data to the original results\n",
    "# df['common_route_count'] = [len(row) for row in df['routes_intersection']]\n",
    "df['common_mode_count'] = [len(row) for row in df['all_modes_intersection']]\n",
    "df['common_transit_mode_count'] = [len(row) for row in df['transit_modes_intersection']]\n",
    "# df['common_agency_count'] = [len(row) for row in df['agency_intersection']]\n",
    "# df['common_stop_count'] = [len(row) for row in df['stops_intersection']]\n",
    "\n",
    "# How many rows have at least one mode in common?\n",
    "df['partial_mode_match'] = [1 if row > 0 else 0 for row in df['common_mode_count']]\n",
    "df['partial_transit_mode_match'] = [1 if row > 0 else 0 for row in df['common_transit_mode_count']]\n",
    "# df['partial_route_match'] = [1 if row > 0 else 0 for row in df['common_route_count']]\n",
    "# df['partial_agency_match'] = [1 if row > 0 else 0 for row in df['common_agency_count']]\n",
    "# df['partial_stop_match'] = [1 if row > 0 else 0 for row in df['common_stop_count']]\n",
    "\n",
    "# Export\n",
    "df.to_csv(OUTPUT_DIR + r'/path_intersection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check if observed path is in pathset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pathset_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Add a field to the new_pathset that lists the pathnum\n",
    "# pathset_links['pathnum'] = pathset_links.index.get_level_values(1)\n",
    "\n",
    "# Join paths based on comparison_field, as defined in script header\n",
    "# Resulting df is merge of all observed paths that have a corresponding path in the pathset for their unique_id\n",
    "# observed paths with no corresponding path in pathset will have NaN for fields \"_pathset\" suffix\n",
    "newdf = pd.merge(observed_path, pathset_paths, how='left',\n",
    "          left_on=['unique_id',comparison_field],right_on=['unique_id',comparison_field], suffixes=['_obs','_pathset'])\n",
    "\n",
    "# Join this data with the pathset path file to get pf_probability associated with the observed path\n",
    "# newdf = pd.merge(df, pathset_paths[['unique_id','pathnum','pf_probability']], \n",
    "#                  left_on=['unique_id','pathnum'], right_on=['unique_id','pathnum'],\n",
    "#                  how='left')\n",
    "\n",
    "# Fields with NaN marked as no match since no matching path was found in pathset\n",
    "newdf['probability'] = newdf['pf_probability'].fillna('no_match')\n",
    "\n",
    "# Grab the highest and lowest probabilities from pathset paths\n",
    "# want to test that the observed path has a reasonably high probability\n",
    "max_prob = newdf.groupby('unique_id').max()['probability']\n",
    "min_prob = newdf.groupby('unique_id').min()['probability']\n",
    "\n",
    "# Reshape those results and export to dataframe\n",
    "prob_export = pd.DataFrame([max_prob,min_prob]).T\n",
    "prob_export.columns = ['max_prob','min_prob']\n",
    "\n",
    "\n",
    "# Reformat at binary to indicate whether a path was found in the pathset\n",
    "prob_export['path_exists'] = prob_export['max_prob'].apply(lambda row_value: 0 if row_value == 'no_match' else 1)\n",
    "prob_export.to_csv('temp_prob_export.csv')\n",
    "\n",
    "# Create a variabale to indicate if the max probability of the observed path\n",
    "# is over a given threshold, as defined at top of script\n",
    "try:\n",
    "    prob_export.ix[prob_export['max_prob'] >= threshold, 'above_threshold'] = 1\n",
    "    prob_export.ix[prob_export['max_prob'] < threshold, 'above_threshold'] = 0\n",
    "    prob_export.ix[prob_export['max_prob'] == 'no_match', 'above_threshold'] = -1\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# export the results probabilities, path_existence, threshold data,\n",
    "# also add the modeled and observed (chosen) path characteristics\n",
    "prob_export['unique_id'] = prob_export.index\n",
    "\n",
    "tempdf = pd.merge(observed_path,modeled_path,on='unique_id',suffixes=['_obs','_model'],how='left')\n",
    "export_df = pd.merge(prob_export,tempdf,on='unique_id',how='left')\n",
    "\n",
    "export_df['person_id'] = export_df['unique_id'].apply(lambda row: row.split(\"_\")[0])\n",
    "export_df['trip_list_id_num'] = export_df['unique_id'].apply(lambda row: row.split(\"_\")[-1])\n",
    "\n",
    "export_df.to_csv(OUTPUT_DIR + '\\path_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07341772151898734"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_df['path_exists'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_exists       1.00000\n",
       "above_threshold   0.44828\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_df[export_df['max_prob'] != 'no_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0379746835443038"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complete_mode_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['complete_agency_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['complete_agency_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
